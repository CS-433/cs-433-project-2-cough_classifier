{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # TODO get GPU\n",
    "\n",
    "from src.utils.get_data import get_data_loader\n",
    "from src.utils.get_data import import_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "fc, lc = import_data(DATA_PATH, segmentation_type='coarse', is_user_features=True,\n",
    "                     return_type='pd')\n",
    "fn, ln = import_data(DATA_PATH, segmentation_type='no', is_user_features=True,\n",
    "                     return_type='pd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance: We observe quite the heavy imbalance, in favor of label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 1229, 1.0: 430})\n",
      "(1659, 72) (1659, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Label', data=ln)\n",
    "print('Original dataset shape %s' % Counter(ln[\"Label\"]))\n",
    "print(fn.shape, ln.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1.0: 1229, 0.0: 1229})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oversample = SMOTE(random_state=42)\n",
    "fn_oversampled, ln_oversampled = oversample.fit_resample(fn, ln)\n",
    "\n",
    "fn_oversampled = pd.DataFrame(fn_oversampled, columns=fn.columns)\n",
    "ln_oversampled = pd.DataFrame(ln_oversampled, columns=ln.columns)\n",
    "\n",
    "sns.countplot(x = 'Label', data=ln_oversampled)\n",
    "print('Resampled dataset shape %s' % Counter(ln_oversampled[\"Label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fn, ln[\"Label\"], test_size=0.33, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN1_DIM = 100\n",
    "HIDDEN2_DIM = 10\n",
    "DROPOUT = 0.1\n",
    "WEIGHT_DECAY = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define Custom Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass trainData(Dataset):\\n    \\n    def __init__(self, X_data, y_data):\\n        self.X_data = X_data\\n        self.y_data = y_data\\n        \\n    def __getitem__(self, index):\\n        return self.X_data[index], self.y_data[index]\\n        \\n    def __len__ (self):\\n        return len(self.X_data)\\n\\n## test data    \\nclass testData(Dataset):\\n    \\n    def __init__(self, X_data):\\n        self.X_data = X_data\\n        \\n    def __getitem__(self, index):\\n        return self.X_data[index]\\n        \\n    def __len__ (self):\\n        return len(self.X_data)\\n    \\n\\ntrain_data = trainData(torch.FloatTensor(X_train), \\n                       torch.FloatTensor(y_train))\\ntest_data = trainData(torch.FloatTensor(X_test), torch.FloatTensor(y_test.values))\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train data\n",
    "\"\"\"\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "test_data = trainData(torch.FloatTensor(X_test), torch.FloatTensor(y_test.values))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_data_loader(\"no\", smote=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define Custom NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden1_dim, hidden2_dim, dropout=0.1):\n",
    "        super(BinaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden1_dim) \n",
    "        self.layer_2 = nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.layer_out = nn.Linear(hidden2_dim, output_dim) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden1_dim)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden2_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 6: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=72, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (layer_out): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BinaryClassification(INPUT_DIM, OUTPUT_DIM, HIDDEN1_DIM, HIDDEN2_DIM, DROPOUT)\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def aoc(y_pred, y_test):\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_test = y_test.detach().numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step X: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.66739 | Acc: 0.640\n",
      "Epoch 002: | Loss: 0.62750 | Acc: 0.723\n",
      "Epoch 003: | Loss: 0.58701 | Acc: 0.794\n",
      "Epoch 004: | Loss: 0.55885 | Acc: 0.824\n",
      "Epoch 005: | Loss: 0.55073 | Acc: 0.834\n",
      "Epoch 006: | Loss: 0.55128 | Acc: 0.836\n",
      "Epoch 007: | Loss: 0.55910 | Acc: 0.823\n",
      "Epoch 008: | Loss: 0.55900 | Acc: 0.832\n",
      "Epoch 009: | Loss: 0.56497 | Acc: 0.825\n",
      "Epoch 010: | Loss: 0.56758 | Acc: 0.828\n",
      "Epoch 011: | Loss: 0.57362 | Acc: 0.822\n",
      "Epoch 012: | Loss: 0.57568 | Acc: 0.820\n",
      "Epoch 013: | Loss: 0.57084 | Acc: 0.840\n",
      "Epoch 014: | Loss: 0.58649 | Acc: 0.814\n",
      "Epoch 015: | Loss: 0.57857 | Acc: 0.833\n",
      "Epoch 016: | Loss: 0.58574 | Acc: 0.822\n",
      "Epoch 017: | Loss: 0.59119 | Acc: 0.821\n",
      "Epoch 018: | Loss: 0.58773 | Acc: 0.825\n",
      "Epoch 019: | Loss: 0.58733 | Acc: 0.837\n",
      "Epoch 020: | Loss: 0.58723 | Acc: 0.841\n",
      "Epoch 021: | Loss: 0.58279 | Acc: 0.853\n",
      "Epoch 022: | Loss: 0.58640 | Acc: 0.844\n",
      "Epoch 023: | Loss: 0.59750 | Acc: 0.835\n",
      "Epoch 024: | Loss: 0.60217 | Acc: 0.833\n",
      "Epoch 025: | Loss: 0.60922 | Acc: 0.823\n",
      "Epoch 026: | Loss: 0.60289 | Acc: 0.850\n",
      "Epoch 027: | Loss: 0.60580 | Acc: 0.842\n",
      "Epoch 028: | Loss: 0.61475 | Acc: 0.839\n",
      "Epoch 029: | Loss: 0.61348 | Acc: 0.853\n",
      "Epoch 030: | Loss: 0.61778 | Acc: 0.837\n",
      "Epoch 031: | Loss: 0.61564 | Acc: 0.862\n",
      "Epoch 032: | Loss: 0.62094 | Acc: 0.852\n",
      "Epoch 033: | Loss: 0.62806 | Acc: 0.839\n",
      "Epoch 034: | Loss: 0.62868 | Acc: 0.856\n",
      "Epoch 035: | Loss: 0.63796 | Acc: 0.831\n",
      "Epoch 036: | Loss: 0.63703 | Acc: 0.859\n",
      "Epoch 037: | Loss: 0.64027 | Acc: 0.853\n",
      "Epoch 038: | Loss: 0.64808 | Acc: 0.832\n",
      "Epoch 039: | Loss: 0.65092 | Acc: 0.839\n",
      "Epoch 040: | Loss: 0.65222 | Acc: 0.851\n",
      "Epoch 041: | Loss: 0.65458 | Acc: 0.850\n",
      "Epoch 042: | Loss: 0.65810 | Acc: 0.848\n",
      "Epoch 043: | Loss: 0.66041 | Acc: 0.854\n",
      "Epoch 044: | Loss: 0.66554 | Acc: 0.826\n",
      "Epoch 045: | Loss: 0.66872 | Acc: 0.829\n",
      "Epoch 046: | Loss: 0.67022 | Acc: 0.846\n",
      "Epoch 047: | Loss: 0.67261 | Acc: 0.841\n",
      "Epoch 048: | Loss: 0.67404 | Acc: 0.852\n",
      "Epoch 049: | Loss: 0.67586 | Acc: 0.849\n",
      "Epoch 050: | Loss: 0.67835 | Acc: 0.838\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        #acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = aoc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    #print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.79186986124579"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step X: Test the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader: # todo for now i onyl include labels from data loader as _ THIS IS BAD! ITS WRONG!\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_test_list.append(y_batch.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "y_test_list = [b.squeeze().tolist() for b in y_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = confusion_matrix(y_test_list, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785714285714286"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.56      0.64       414\n",
      "         1.0       0.64      0.80      0.71       398\n",
      "\n",
      "    accuracy                           0.68       812\n",
      "   macro avg       0.69      0.68      0.67       812\n",
      "weighted avg       0.69      0.68      0.67       812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "first off, you wouldn't shuffle your test loader.\n",
    "\n",
    "Here's an example:\n",
    " \n",
    "batch_size = 20  \n",
    "class_sample_count = [10, 1, 20, 3, 4] # dataset has 10 class-1 samples, 1 class-2 samples, etc.  \n",
    "weights = 1 / torch.Tensor(class_sample_count)  \n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, batch_size)  \n",
    "trainloader = data_utils.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, sampler = sampler) \n",
    "\n",
    "I THINK THIS OR SMOTE: BASICALLY THIS IS DEFAULT OVERSAMPLING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}